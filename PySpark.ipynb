{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tprQu6BYOQ5M",
        "outputId": "7b456d7e-cf46-4fc9-abc3-049a2d7a4091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=30c500897488b80aa4cb5771ab4d57ee359d2fc8c5794893fcd27207554ca336\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PySpark require a session to run clusters"
      ],
      "metadata": {
        "id": "CcyLjDlDSasm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Import the spark session builder\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "      .appName(\"MySparkSession\") \\\n",
        "      .master(\"local[2]\") \\\n",
        "      .getOrCreate()"
      ],
      "metadata": {
        "id": "gHJH7p2XOo1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f1TL_w35SZGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd2yxW6XPYaY",
        "outputId": "ca696d29-95c2-470b-8734-8c7e91f8505c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Basic of PySpark"
      ],
      "metadata": {
        "id": "kf-8ptKFgPDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading a file\n",
        "prev = spark.read.csv(\"block_1.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Rename the columns using toDF and assign the result to a new DataFrame\n",
        "prev_renamed = prev.toDF(\"col1\", \"col2\", \"CMPfirstnameFIRST\", \"CMPfirstnameFIRST\", \"CMPlastnameFIRST\", \"CMPlastnameLAST\", \"sex\", \"col8\", \"col9\", \"col10\", \"col11\", \"col12\")\n",
        "\n",
        "# Show the original DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "prev.show()\n",
        "\n",
        "# Show the DataFrame with renamed columns\n",
        "print(\"\\nDataFrame with Renamed Columns:\")\n",
        "prev_renamed.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS_q0gKnPhUm",
        "outputId": "0b0e9ccf-866c-46b5-e61f-ff041eb681c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
            "| id_1| id_2|     cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
            "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
            "|37291|53113|0.833333333333333|           ?|         1.0|           ?|      1|     1|     1|     1|      0|    true|\n",
            "|39086|47614|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|70031|70237|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|84795|97439|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|36950|42116|                1|           ?|         1.0|           1|      1|     1|     1|     1|      1|    true|\n",
            "|42413|48491|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|25965|64753|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|49451|90407|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      0|    true|\n",
            "|39932|40902|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|46626|47940|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|48948|98379|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "| 4767| 4826|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|45463|69659|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|11367|13169|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|10782|89636|                1|           ?|         1.0|           ?|      1|     0|     1|     1|      1|    true|\n",
            "|26206|39147|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|16662|27083|                1|           1|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|18823|30204|                1|           1|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|38545|85418|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|28963|39172|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
            "only showing top 20 rows\n",
            "\n",
            "\n",
            "DataFrame with Renamed Columns:\n",
            "+-----+-----+-----------------+-----------------+----------------+---------------+---+----+----+-----+-----+-----+\n",
            "| col1| col2|CMPfirstnameFIRST|CMPfirstnameFIRST|CMPlastnameFIRST|CMPlastnameLAST|sex|col8|col9|col10|col11|col12|\n",
            "+-----+-----+-----------------+-----------------+----------------+---------------+---+----+----+-----+-----+-----+\n",
            "|37291|53113|0.833333333333333|                ?|             1.0|              ?|  1|   1|   1|    1|    0| true|\n",
            "|39086|47614|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|70031|70237|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|84795|97439|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|36950|42116|                1|                ?|             1.0|              1|  1|   1|   1|    1|    1| true|\n",
            "|42413|48491|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|25965|64753|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|49451|90407|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    0| true|\n",
            "|39932|40902|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|46626|47940|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|48948|98379|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "| 4767| 4826|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|45463|69659|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|11367|13169|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|10782|89636|                1|                ?|             1.0|              ?|  1|   0|   1|    1|    1| true|\n",
            "|26206|39147|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|16662|27083|                1|                1|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|18823|30204|                1|                1|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|38545|85418|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "|28963|39172|                1|                ?|             1.0|              ?|  1|   1|   1|    1|    1| true|\n",
            "+-----+-----+-----------------+-----------------+----------------+---------------+---+----+----+-----+-----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyzing Data with the DataFrame API"
      ],
      "metadata": {
        "id": "dV1LVU1bLwxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prev.printSchema() #prev.info() in pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb6ytXq0Svfw",
        "outputId": "7ae3ae74-8b22-43a0-eae1-6fce6ee52148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id_1: integer (nullable = true)\n",
            " |-- id_2: integer (nullable = true)\n",
            " |-- cmp_fname_c1: string (nullable = true)\n",
            " |-- cmp_fname_c2: string (nullable = true)\n",
            " |-- cmp_lname_c1: double (nullable = true)\n",
            " |-- cmp_lname_c2: string (nullable = true)\n",
            " |-- cmp_sex: integer (nullable = true)\n",
            " |-- cmp_bd: string (nullable = true)\n",
            " |-- cmp_bm: string (nullable = true)\n",
            " |-- cmp_by: string (nullable = true)\n",
            " |-- cmp_plz: string (nullable = true)\n",
            " |-- is_match: boolean (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prev.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMcZZ8-BbEwI",
        "outputId": "63b97a09-1b74-4d67-dd0e-43af5ab0f000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
            "| id_1| id_2|     cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
            "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
            "|37291|53113|0.833333333333333|           ?|         1.0|           ?|      1|     1|     1|     1|      0|    true|\n",
            "|39086|47614|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|70031|70237|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|84795|97439|                1|           ?|         1.0|           ?|      1|     1|     1|     1|      1|    true|\n",
            "|36950|42116|                1|           ?|         1.0|           1|      1|     1|     1|     1|      1|    true|\n",
            "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You access the methods of the DataFrameReader API by calling the read method on a SparkSession instance, and you can load data from a file using either the format and load methods or one of the shortcut methods for built-in formats:"
      ],
      "metadata": {
        "id": "ca0ULhtbZC-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = spark.read.format(\"json\").load(\"file.json\")\n",
        "d2 = spark.read.json(\"file.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "IQd8aJHuV4sR",
        "outputId": "9798bb31-f3af-43b0-80c6-691442d19e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-8f2fe3195460>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/file.json."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main difference lies in the level of control and customization. If you have specific requirements or need to set detailed options for reading JSON files, you might prefer using the format(\"json\").load(\"file.json\") approach.\n",
        "\n",
        "On the other hand, if you have a standard JSON file and want a concise and simple way to read it into a DataFrame, the read.json(\"file.json\") method is a convenient shortcut."
      ],
      "metadata": {
        "id": "x3jd9hTWZI6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#counting the number of row\n",
        "prev.count()"
      ],
      "metadata": {
        "id": "IB0psOD6Yuuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After schema inference, only what specified can run on the infered datatype\n",
        "#so if we want to save that datatypes, we must save it to cache\n",
        "prev.cache()"
      ],
      "metadata": {
        "id": "ZOqT5ivGa_nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev.groupBy(\"is_match\").count().orderBy(col(\"count\").desc()).show()\n",
        "\n",
        "\"\"\"\n",
        "SELECT is_match, COUNT(*) AS count\n",
        "    FROM prev\n",
        "    GROUP BY is_match\n",
        "    ORDER BY count DESC\n",
        "\n",
        "for SparkSQL\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TJdwv6nQcxPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DataFrame Aggregation functions"
      ],
      "metadata": {
        "id": "9-MurVDlNruQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prev.printSchema()"
      ],
      "metadata": {
        "id": "498ADxy9UNHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print out the average and standard deviation\n",
        "prev.agg(avg(\"cmp_sex\"), stddev(\"cmp_sex\")).show()"
      ],
      "metadata": {
        "id": "GuQ_a9jTOEb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic aggregate functions\n",
        "\n",
        "# Print the number of row in the dataset\n",
        "print(\"Count: \", prev.select(count(\"*\").alias(\"row_count\")).first()[\"row_count\"])\n",
        "\n",
        "# Print the sum of the 'cmp_sex' column\n",
        "print(\"Sum:\", prev.select(sum(\"cmp_sex\").alias(\"total_sex\")).first()[\"total_sex\"])\n",
        "\n",
        "# Print the average of the 'cmp_lname_c1' column\n",
        "print(\"Average:\", prev.select(avg(\"cmp_lname_c1\").alias(\"avg_cmp_lname_c1\")).first()[\"avg_cmp_lname_c1\"])\n",
        "\n",
        "# Print the maximum and minimum values of the 'cmp_bd' column\n",
        "max_min = prev.select(max(\"cmp_bd\").alias(\"max_cmp_bd\"), min(\"cmp_bd\").alias(\"min_cmp_bd\")).first()\n",
        "print(\"Max and Min:\", max_min[\"max_cmp_bd\"], max_min[\"min_cmp_bd\"])\n",
        "\n",
        "# Print the distinct values in the 'cmp_plz' column\n",
        "print(\"Distinct Values:\", prev.select(\"cmp_plz\").distinct().rdd.flatMap(lambda x: x).collect())\n",
        "\n",
        "# Print the standard deviation of the 'cmp_lname_c1' column\n",
        "print(\"Standard Deviation:\", prev.select(stddev(\"cmp_lname_c1\").alias(\"stddev_cmp_lname_c1\")).first()[\"stddev_cmp_lname_c1\"])\n",
        "\n",
        "# Print the variance of the 'cmp_lname_c1' column\n",
        "print(\"Variance:\", prev.select(variance(\"cmp_lname_c1\").alias(\"variance_cmp_lname_c1\")).first()[\"variance_cmp_lname_c1\"])\n",
        "\n",
        "# Print the correlation between 'cmp_sex' and 'cmp_lname_c1'\n",
        "print(\"Correlation:\", prev.select(corr(\"cmp_sex\", \"cmp_lname_c1\").alias(\"correlation\")).first()[\"correlation\"])\n",
        "\n",
        "# Print the covariance between 'cmp_sex' and 'cmp_lname_c1'\n",
        "print(\"Covariance:\", prev.select(covar_samp(\"cmp_sex\", \"cmp_lname_c1\").alias(\"covariance\")).first()[\"covariance\"])\n",
        "\n",
        "# Print the first element of the 'cmp_plz' column\n",
        "print(\"First Element:\", prev.select(first(\"cmp_plz\").alias(\"first_element\")).first()[\"first_element\"])\n",
        "\n",
        "# Print the last element of the 'cmp_plz' column\n",
        "print(\"Last Element:\", prev.select(last(\"cmp_plz\").alias(\"last_element\")).first()[\"last_element\"])\n"
      ],
      "metadata": {
        "id": "BaWecULRVicZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tabular format\n",
        "prev.agg(\n",
        "    avg(\"cmp_sex\").alias(\"avg_cmp_sex\"),\n",
        "    stddev(\"cmp_sex\").alias(\"stddev_cmp_sex\"),\n",
        "    max(\"cmp_sex\").alias(\"max_cmp_sex\"),\n",
        "    min(\"cmp_sex\").alias(\"min_cmp_sex\"),\n",
        "    variance(\"cmp_sex\").alias(\"variance_cmp_sex\"),\n",
        "    corr(\"cmp_sex\", \"cmp_lname_c1\").alias(\"correlation_cmp_sex\"),\n",
        "    covar_samp(\"cmp_sex\", \"cmp_lname_c1\").alias(\"covariance_cmp_sex\"),\n",
        "    first(\"cmp_sex\").alias(\"first_cmp_sex\"),\n",
        "    last(\"cmp_sex\").alias(\"last_cmp_sex\")\n",
        ").show()\n"
      ],
      "metadata": {
        "id": "mVvzWpIpZscp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have the option of running Spark either by using an ANSI 2003-compliant version of Spark SQL (the default) or in HiveQL mode by calling the enableHiveSupport method when you create a SparkSession instance via its Builder API."
      ],
      "metadata": {
        "id": "vbJrd3oNe40m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This method allow us to create a new view named inside the parameter and use SQL inside the\n",
        "# python code and can be call upon\n",
        "prev.createOrReplaceTempView(\"linkage\")"
      ],
      "metadata": {
        "id": "3UWKSyEbcryv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "  Select id_1, is_match\n",
        "  From linkage\n",
        "\"\"\").show()\n",
        "\n",
        "# You can use all kind of SQL queries using SparkSQL"
      ],
      "metadata": {
        "id": "RalEFWVkdpbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can connect to a Hive metastore via a hive-site.xml file, and you can also use HiveQL in queries by calling the enableHiveSupport method on the SparkSession Builder API. However, using SparkSQL will allow the application to handle data more fluently between spark environment\n",
        "\n"
      ],
      "metadata": {
        "id": "rl3rV6D3e-ZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_session = SparkSession.builder.master(\"local[4]\").\\\n",
        "                  enableHiveSupport().getOrCreate()"
      ],
      "metadata": {
        "id": "hhcmMiPzehb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fast summary statistics for DataFrames"
      ],
      "metadata": {
        "id": "hrEaO05af42Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although there are many kinds of analyses that may be expressed equally well in SQL or with the DataFrame API, there are certain common things that we want to be able to do with dataframes that can be tedious to express in SQL. One such analysis that is especially helpful is computing the min, max, mean, and standard deviation of all the non-null values in the numerical columns of a dataframe. In PySpark, this function has the same name that it does in pandas"
      ],
      "metadata": {
        "id": "GZNEKYEOgwEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The .describe() function in PySpark provides summary statistics for numeric\n",
        "# columns in a DataFrame, including count, mean, standard deviation, minimum, and\n",
        "# maximum values. It helps to quickly analyze the distribution and characteristics\n",
        "# of numerical data.\n",
        "summary = prev.describe()\n",
        "summary.show()\n",
        "\n",
        "print(\"Select specific column\")\n",
        "summary.select(\"summary\", \"cmp_fname_c1\", \"cmp_fname_c2\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbmb3zVcf3b-",
        "outputId": "d7a1d257-2698-4703-c5e9-61a25dd3a489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+\n",
            "|summary|              id_1|             id_2|      cmp_fname_c1|      cmp_fname_c2|       cmp_lname_c1|       cmp_lname_c2|            cmp_sex|             cmp_bd|             cmp_bm|             cmp_by|             cmp_plz|\n",
            "+-------+------------------+-----------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+\n",
            "|  count|            574913|           574913|            574913|            574913|             574913|             574913|             574913|             574913|             574913|             574913|              574913|\n",
            "|   mean|33271.962171667714| 66564.6636865056|0.7127592938252765|0.8977586763518972|0.31557245780987964|0.32691554145529067| 0.9550923357099248|0.22475563232907309| 0.4886361857246487|0.22266639529199742|0.005494946113964...|\n",
            "| stddev| 23622.66942593358|23642.00230967225|0.3889286452463553|0.2742577520430534| 0.3342494687554251|0.37830920205406704|0.20710152240504406| 0.4174216587235586|0.49987128182816276|  0.416036504164562| 0.07392402321301904|\n",
            "|    min|                 1|                6|                 0|                 0|                0.0|                  0|                  0|                  0|                  0|                  0|                   0|\n",
            "|    max|             99894|           100000|                 ?|                 ?|                1.0|                  ?|                  1|                  ?|                  ?|                  ?|                   ?|\n",
            "+-------+------------------+-----------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------------+\n",
            "\n",
            "Select specific column\n",
            "+-------+------------------+------------------+\n",
            "|summary|      cmp_fname_c1|      cmp_fname_c2|\n",
            "+-------+------------------+------------------+\n",
            "|  count|            574913|            574913|\n",
            "|   mean|0.7127592938252765|0.8977586763518972|\n",
            "| stddev|0.3889286452463553|0.2742577520430534|\n",
            "|    min|                 0|                 0|\n",
            "|    max|                 ?|                 ?|\n",
            "+-------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data filtering\n",
        "\n",
        "matches = prev.where(\"is_match = true\")\n",
        "match_summary = matches.describe().show()\n",
        "\n",
        "misses = prev.filter(col(\"is_match\") == False)\n",
        "miss_summary = misses.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA48Aalwg2CP",
        "outputId": "5415ed72-3583-4040-9873-9c7a4a1eb4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----------------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|summary|              id_1|             id_2|       cmp_fname_c1|       cmp_fname_c2|        cmp_lname_c1|       cmp_lname_c2|            cmp_sex|             cmp_bd|             cmp_bm|             cmp_by|            cmp_plz|\n",
            "+-------+------------------+-----------------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|  count|              2093|             2093|               2093|               2093|                2093|               2093|               2093|               2093|               2093|               2093|               2093|\n",
            "|   mean| 34440.86956521739|50889.32345914955| 0.9970329792424486| 0.9955357142857143|   0.997560095051734|  0.960167714884696| 0.9894887720974678| 0.9952221691352127| 0.9976110845676063| 0.9961777353081701| 0.9545236955481091|\n",
            "| stddev|21743.893698458884| 24382.2927756227|0.03979189523588238|0.05050762722761048|0.039218983113320234|0.17815710016004582|0.10200839997032067|0.06897301025106671|0.04882978308841625|0.06172094528780762|0.20839625610356813|\n",
            "|    min|                 5|                6|                  0|  0.428571428571429|                 0.0|                  0|                  0|                  0|                  0|                  0|                  0|\n",
            "|    max|             98459|            99897|                  ?|                  ?|                 1.0|                  ?|                  1|                  1|                  1|                  1|                  ?|\n",
            "+-------+------------------+-----------------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "\n",
            "+-------+------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+-------------------+------------------+-------------------+--------------------+\n",
            "|summary|              id_1|              id_2|      cmp_fname_c1|      cmp_fname_c2|       cmp_lname_c1|       cmp_lname_c2|           cmp_sex|             cmp_bd|            cmp_bm|             cmp_by|             cmp_plz|\n",
            "+-------+------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+-------------------+------------------+-------------------+--------------------+\n",
            "|  count|            572820|            572820|            572820|            572820|             572820|             572820|            572820|             572820|            572820|             572820|              572820|\n",
            "|   mean|33267.691156035056| 66621.93907335638|0.7117214109571942| 0.896531309395388|0.31308057532542455|0.14647271784368557| 0.954966656192172|0.22194015622653895|0.4867762650194323|0.21983979272223172|0.002026143905208...|\n",
            "| stddev| 23629.17173939819|23620.209907934994|0.3892503865780554|0.2756960039526614| 0.3322945432692614|0.16606808591409788|0.2073774742588524| 0.4155514706682478|0.4998255385763446|0.41413833160537966| 0.04496712336847972|\n",
            "|    min|                 1|               136|                 0|                 0|                0.0|                  0|                 0|                  0|                 0|                  0|                   0|\n",
            "|    max|             99894|            100000|                 ?|                 ?|                1.0|                  ?|                 1|                  ?|                 ?|                  ?|                   ?|\n",
            "+-------+------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+-------------------+------------------+-------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pivoting and reshaping DataFrames"
      ],
      "metadata": {
        "id": "cpRxR5yli83v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can transpose the DataFrames entirely using functions provided by PySpark. However, there is another way to perform this task. PySpark allows conversion between Spark and pandas DataFrames. We will convert the DataFrames in question into pandas DataFrames, reshape them, and convert them back to Spark DataFrames"
      ],
      "metadata": {
        "id": "X3IWxPpfkvnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_p = summary.toPandas()\n",
        "summary_p.head()\n",
        "\n",
        "summary_p.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUkLTioajBvb",
        "outputId": "4c57e7ee-917e-4472-d796-d6f93c04cc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_p = summary_p.set_index('summary').transpose().reset_index()\n",
        "...\n",
        "summary_p = summary_p.rename(columns={'index':'field'})\n",
        "...\n",
        "summary_p = summary_p.rename_axis(None, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "jjvLNPhHk_-n",
        "outputId": "422ab99d-ba06-42cc-9f48-0f826434aef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6001\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6002\u001b[0;31m                     \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6003\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5288\u001b[0m         \"\"\"\n\u001b[0;32m-> 5289\u001b[0;31m         \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5290\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'DataFrame'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-a304174bb0a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msummary_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'field'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msummary_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6002\u001b[0m                     \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6003\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6004\u001b[0;31m                     raise TypeError(\n\u001b[0m\u001b[1;32m   6005\u001b[0m                         \u001b[0;34mf\"{err_msg}. Received column of type {type(col)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6006\u001b[0m                     ) from err\n",
            "\u001b[0;31mTypeError\u001b[0m: The parameter \"keys\" may be a column key, one-dimensional array, or a list containing only valid column keys and one-dimensional arrays.. Received column of type <class 'pandas.core.frame.DataFrame'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summaryT = spark.createDataFrame(summary_p)\n",
        "...\n",
        "summaryT.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBqva_helX84",
        "outputId": "c5bf6206-a6b3-4c0f-e119-25e6d4268944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------+--------------------+-------------------+---+------+\n",
            "|       field| count|                mean|             stddev|min|   max|\n",
            "+------------+------+--------------------+-------------------+---+------+\n",
            "|        id_1|574913|  33271.962171667714|  23622.66942593358|  1| 99894|\n",
            "|        id_2|574913|    66564.6636865056|  23642.00230967225|  6|100000|\n",
            "|cmp_fname_c1|574913|  0.7127592938252765| 0.3889286452463553|  0|     ?|\n",
            "|cmp_fname_c2|574913|  0.8977586763518972| 0.2742577520430534|  0|     ?|\n",
            "|cmp_lname_c1|574913| 0.31557245780987964| 0.3342494687554251|0.0|   1.0|\n",
            "|cmp_lname_c2|574913| 0.32691554145529067|0.37830920205406704|  0|     ?|\n",
            "|     cmp_sex|574913|  0.9550923357099248|0.20710152240504406|  0|     1|\n",
            "|      cmp_bd|574913| 0.22475563232907309| 0.4174216587235586|  0|     ?|\n",
            "|      cmp_bm|574913|  0.4886361857246487|0.49987128182816276|  0|     ?|\n",
            "|      cmp_by|574913| 0.22266639529199742|  0.416036504164562|  0|     ?|\n",
            "|     cmp_plz|574913|0.005494946113964...|0.07392402321301904|  0|     ?|\n",
            "+------------+------+--------------------+-------------------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Joining DataFrame and selecting Features"
      ],
      "metadata": {
        "id": "uQ6DCzYjnf0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have used Spark SQL and the DataFrame API only to filter and aggregate the records from a dataset, but we can also use these tools to perform joins (inner, left outer, right outer, or full outer) on DataFrames. Although the DataFrame API includes a join function, it’s often easier to express these joins using Spark SQL, especially when the tables we are joining have a large number of column names in common and we want to be able to clearly indicate which column we are referring to in our select expressions"
      ],
      "metadata": {
        "id": "taKrRT07oyA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "match_summaryT = pivot_summary(match_summary)\n",
        "miss_summaryT = pivot_summary(miss_summary)\n",
        "\n",
        "match_summaryT.createOrReplaceTempView(\"match_desc\")\n",
        "miss_summaryT.createOrReplaceTempView(\"miss_desc\")\n",
        "spark.sql(\"\"\"\n",
        "  SELECT a.field, a.count + b.count total, a.mean - b.mean delta\n",
        "  FROM match_desc a INNER JOIN miss_desc b ON a.field = b.field\n",
        "  WHERE a.field NOT IN (\"id_1\", \"id_2\")\n",
        "  ORDER BY delta DESC, total DESC\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "B_L12SdgnkuF",
        "outputId": "e867254c-88c0-4a28-c3ce-54a5dcdd39a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dfc0faa9042a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatch_summaryT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmiss_summaryT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmiss_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmatch_summaryT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateOrReplaceTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"match_desc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmiss_summaryT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateOrReplaceTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"miss_desc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'match_summary' is not defined"
          ]
        }
      ]
    }
  ]
}